{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "e57b6991",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append(\"..\")\n",
    "\n",
    "import pandas as pd\n",
    "from tabulate import tabulate\n",
    "import talib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "0e2dae09",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading stock data from CSV files\n"
     ]
    }
   ],
   "source": [
    "print(\"Loading stock data from CSV files\")\n",
    "tickers = [\"AAPL\", \"AMZN\", \"GOOG\", \"META\", \"MSFT\", \"NVDA\"]\n",
    "\n",
    "stock_data = {}\n",
    "\n",
    "for t in tickers:\n",
    "    df = pd.read_csv(f\"../data/finance_data/{t}.csv\")\n",
    "    stock_data[t] = df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "5b8911bd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Checking for missing values in each dataset:\n",
      "\n",
      "Summary statistics for AAPL:\n",
      "+----------+------------------+\n",
      "| Column   |   Missing Values |\n",
      "|----------+------------------|\n",
      "| Date     |                0 |\n",
      "| Close    |                0 |\n",
      "| High     |                0 |\n",
      "| Low      |                0 |\n",
      "| Open     |                0 |\n",
      "| Volume   |                0 |\n",
      "+----------+------------------+\n",
      "\n",
      "Summary statistics for AMZN:\n",
      "+----------+------------------+\n",
      "| Column   |   Missing Values |\n",
      "|----------+------------------|\n",
      "| Date     |                0 |\n",
      "| Close    |                0 |\n",
      "| High     |                0 |\n",
      "| Low      |                0 |\n",
      "| Open     |                0 |\n",
      "| Volume   |                0 |\n",
      "+----------+------------------+\n",
      "\n",
      "Summary statistics for GOOG:\n",
      "+----------+------------------+\n",
      "| Column   |   Missing Values |\n",
      "|----------+------------------|\n",
      "| Date     |                0 |\n",
      "| Close    |                0 |\n",
      "| High     |                0 |\n",
      "| Low      |                0 |\n",
      "| Open     |                0 |\n",
      "| Volume   |                0 |\n",
      "+----------+------------------+\n",
      "\n",
      "Summary statistics for META:\n",
      "+----------+------------------+\n",
      "| Column   |   Missing Values |\n",
      "|----------+------------------|\n",
      "| Date     |                0 |\n",
      "| Close    |                0 |\n",
      "| High     |                0 |\n",
      "| Low      |                0 |\n",
      "| Open     |                0 |\n",
      "| Volume   |                0 |\n",
      "+----------+------------------+\n",
      "\n",
      "Summary statistics for MSFT:\n",
      "+----------+------------------+\n",
      "| Column   |   Missing Values |\n",
      "|----------+------------------|\n",
      "| Date     |                0 |\n",
      "| Close    |                0 |\n",
      "| High     |                0 |\n",
      "| Low      |                0 |\n",
      "| Open     |                0 |\n",
      "| Volume   |                0 |\n",
      "+----------+------------------+\n",
      "\n",
      "Summary statistics for NVDA:\n",
      "+----------+------------------+\n",
      "| Column   |   Missing Values |\n",
      "|----------+------------------|\n",
      "| Date     |                0 |\n",
      "| Close    |                0 |\n",
      "| High     |                0 |\n",
      "| Low      |                0 |\n",
      "| Open     |                0 |\n",
      "| Volume   |                0 |\n",
      "+----------+------------------+\n"
     ]
    }
   ],
   "source": [
    "print(\"Checking for missing values in each dataset:\")\n",
    "for ticker, df in stock_data.items():\n",
    "    print(f\"\\nSummary statistics for {ticker}:\")\n",
    "    missing_summary = df.isna().sum().reset_index()\n",
    "    missing_summary.columns = ['Column', 'Missing Values']\n",
    "    print(tabulate(missing_summary, headers=\"keys\", tablefmt=\"psql\", showindex=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "1567953e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cleaning and aligning datasets:\n",
      "+----------+---------------+--------------+----------------------+----------------+\n",
      "| Ticker   |   Rows Before |   Rows After |   Duplicates Removed | Date dtype     |\n",
      "|----------+---------------+--------------+----------------------+----------------|\n",
      "| AAPL     |          3774 |         2923 |                  851 | datetime64[ns] |\n",
      "| AMZN     |          3774 |         2923 |                  851 | datetime64[ns] |\n",
      "| GOOG     |          3774 |         2923 |                  851 | datetime64[ns] |\n",
      "| META     |          2923 |         2923 |                    0 | datetime64[ns] |\n",
      "| MSFT     |          3774 |         2923 |                  851 | datetime64[ns] |\n",
      "| NVDA     |          3774 |         2923 |                  851 | datetime64[ns] |\n",
      "+----------+---------------+--------------+----------------------+----------------+\n"
     ]
    }
   ],
   "source": [
    "print(\"Cleaning and aligning datasets:\")\n",
    "\n",
    "summary = []\n",
    "\n",
    "date_sets = [set(pd.to_datetime(df[\"Date\"])) for df in stock_data.values()]\n",
    "common_dates = set.intersection(*date_sets)\n",
    "\n",
    "for ticker, df in stock_data.items():\n",
    "    before_rows = df.shape[0]\n",
    "\n",
    "    # Convert Date column to datetime\n",
    "    df[\"Date\"] = pd.to_datetime(df[\"Date\"], errors=\"coerce\")\n",
    "\n",
    "    # Drop duplicates\n",
    "    df.drop_duplicates(subset=\"Date\", inplace=True)\n",
    "\n",
    "    # Filter to common dates\n",
    "    df = df[df[\"Date\"].isin(common_dates)].copy()\n",
    "\n",
    "    # Sort by date\n",
    "    df.sort_values(\"Date\", inplace=True)\n",
    "\n",
    "    # Adjust index\n",
    "    df.reset_index(drop=True, inplace=True)\n",
    "\n",
    "    # Get after rows\n",
    "    after_rows = df.shape[0]\n",
    "\n",
    "    # Save back to dictionary\n",
    "    stock_data[ticker] = df\n",
    "\n",
    "    summary.append(\n",
    "        {\n",
    "            \"Ticker\": ticker,\n",
    "            \"Rows Before\": before_rows,\n",
    "            \"Rows After\": after_rows,\n",
    "            \"Duplicates Removed\": before_rows - after_rows,\n",
    "            \"Date dtype\": df[\"Date\"].dtype,\n",
    "        }\n",
    "    )\n",
    "\n",
    "print(tabulate(summary, headers=\"keys\", tablefmt=\"psql\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "278ea4f2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Analysis with TA-Lib\n",
      "+----------+--------------+----------+----------+----------+--------+---------------+-------------+\n",
      "| Ticker   |   Total Rows |   SMA_20 |   EMA_20 |   RSI_14 |   MACD |   MACD_Signal |   MACD_Hist |\n",
      "|----------+--------------+----------+----------+----------+--------+---------------+-------------|\n",
      "| AAPL     |         2923 |   192.49 |   191.43 |    51.12 | 1.5595 |        2.4246 |     -0.8651 |\n",
      "| AMZN     |         2923 |   149.82 |   150.21 |    59.01 | 2.782  |        2.923  |     -0.141  |\n",
      "| GOOG     |         2923 |   135.98 |   137.41 |    59.31 | 1.8428 |        1.3059 |      0.5369 |\n",
      "| META     |         2923 |   336.87 |   341.66 |    64.3  | 8.1933 |        6.6935 |      1.4998 |\n",
      "| MSFT     |         2923 |   367.79 |   367.79 |    57.95 | 2.6536 |        3.1496 |     -0.496  |\n",
      "| NVDA     |         2923 |    48.05 |    48.49 |    58.31 | 0.6975 |        0.6352 |      0.0624 |\n",
      "+----------+--------------+----------+----------+----------+--------+---------------+-------------+\n"
     ]
    }
   ],
   "source": [
    "print(\"Analysis with TA-Lib\")\n",
    "\n",
    "indicators_data = {}\n",
    "summary = []\n",
    "\n",
    "for ticker, df in stock_data.items():\n",
    "    temp = df.copy()\n",
    "\n",
    "    temp[\"SMA_20\"] = talib.SMA(temp[\"Close\"], timeperiod=20)\n",
    "\n",
    "    temp[\"EMA_20\"] = talib.EMA(temp[\"Close\"], timeperiod=20)\n",
    "\n",
    "    temp[\"RSI_14\"] = talib.RSI(temp[\"Close\"], timeperiod=14)\n",
    "\n",
    "    macd, macd_signal, macd_hist = talib.MACD(\n",
    "        temp[\"Close\"], fastperiod=12, slowperiod=26, signalperiod=9\n",
    "    )\n",
    "    temp[\"MACD\"] = macd\n",
    "    temp[\"MACD_Signal\"] = macd_signal\n",
    "    temp[\"MACD_Hist\"] = macd_hist\n",
    "\n",
    "    indicators_data[ticker] = temp\n",
    "    last_row = temp.iloc[-1]\n",
    "    summary.append(\n",
    "        {\n",
    "            \"Ticker\": ticker,\n",
    "            \"Total Rows\": temp.shape[0],\n",
    "            \"SMA_20\": round(last_row[\"SMA_20\"], 2),\n",
    "            \"EMA_20\": round(last_row[\"EMA_20\"], 2),\n",
    "            \"RSI_14\": round(last_row[\"RSI_14\"], 2),\n",
    "            \"MACD\": round(last_row[\"MACD\"], 4),\n",
    "            \"MACD_Signal\": round(last_row[\"MACD_Signal\"], 4),\n",
    "            \"MACD_Hist\": round(last_row[\"MACD_Hist\"], 4),\n",
    "        }\n",
    "    )\n",
    "\n",
    "print(tabulate(summary, headers=\"keys\", tablefmt=\"psql\"))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
