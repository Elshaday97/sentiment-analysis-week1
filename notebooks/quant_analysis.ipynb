{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "e57b6991",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append(\"..\")\n",
    "\n",
    "import pandas as pd\n",
    "from tabulate import tabulate\n",
    "import talib\n",
    "import pynance as pn\n",
    "import empyrical as ep"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "0e2dae09",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading stock data from CSV files\n"
     ]
    }
   ],
   "source": [
    "print(\"Loading stock data from CSV files\")\n",
    "tickers = [\"AAPL\", \"AMZN\", \"GOOG\", \"META\", \"MSFT\", \"NVDA\"]\n",
    "\n",
    "stock_data = {}\n",
    "\n",
    "for t in tickers:\n",
    "    df = pd.read_csv(f\"../data/finance_data/{t}.csv\")\n",
    "    stock_data[t] = df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "5b8911bd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Checking for missing values in each dataset:\n",
      "\n",
      "Summary statistics for AAPL:\n",
      "+----------+------------------+\n",
      "| Column   |   Missing Values |\n",
      "|----------+------------------|\n",
      "| Date     |                0 |\n",
      "| Close    |                0 |\n",
      "| High     |                0 |\n",
      "| Low      |                0 |\n",
      "| Open     |                0 |\n",
      "| Volume   |                0 |\n",
      "+----------+------------------+\n",
      "\n",
      "Summary statistics for AMZN:\n",
      "+----------+------------------+\n",
      "| Column   |   Missing Values |\n",
      "|----------+------------------|\n",
      "| Date     |                0 |\n",
      "| Close    |                0 |\n",
      "| High     |                0 |\n",
      "| Low      |                0 |\n",
      "| Open     |                0 |\n",
      "| Volume   |                0 |\n",
      "+----------+------------------+\n",
      "\n",
      "Summary statistics for GOOG:\n",
      "+----------+------------------+\n",
      "| Column   |   Missing Values |\n",
      "|----------+------------------|\n",
      "| Date     |                0 |\n",
      "| Close    |                0 |\n",
      "| High     |                0 |\n",
      "| Low      |                0 |\n",
      "| Open     |                0 |\n",
      "| Volume   |                0 |\n",
      "+----------+------------------+\n",
      "\n",
      "Summary statistics for META:\n",
      "+----------+------------------+\n",
      "| Column   |   Missing Values |\n",
      "|----------+------------------|\n",
      "| Date     |                0 |\n",
      "| Close    |                0 |\n",
      "| High     |                0 |\n",
      "| Low      |                0 |\n",
      "| Open     |                0 |\n",
      "| Volume   |                0 |\n",
      "+----------+------------------+\n",
      "\n",
      "Summary statistics for MSFT:\n",
      "+----------+------------------+\n",
      "| Column   |   Missing Values |\n",
      "|----------+------------------|\n",
      "| Date     |                0 |\n",
      "| Close    |                0 |\n",
      "| High     |                0 |\n",
      "| Low      |                0 |\n",
      "| Open     |                0 |\n",
      "| Volume   |                0 |\n",
      "+----------+------------------+\n",
      "\n",
      "Summary statistics for NVDA:\n",
      "+----------+------------------+\n",
      "| Column   |   Missing Values |\n",
      "|----------+------------------|\n",
      "| Date     |                0 |\n",
      "| Close    |                0 |\n",
      "| High     |                0 |\n",
      "| Low      |                0 |\n",
      "| Open     |                0 |\n",
      "| Volume   |                0 |\n",
      "+----------+------------------+\n"
     ]
    }
   ],
   "source": [
    "print(\"Checking for missing values in each dataset:\")\n",
    "for ticker, df in stock_data.items():\n",
    "    print(f\"\\nSummary statistics for {ticker}:\")\n",
    "    missing_summary = df.isna().sum().reset_index()\n",
    "    missing_summary.columns = ['Column', 'Missing Values']\n",
    "    print(tabulate(missing_summary, headers=\"keys\", tablefmt=\"psql\", showindex=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "1567953e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cleaning and aligning datasets:\n",
      "+----------+---------------+--------------+----------------------+----------------+\n",
      "| Ticker   |   Rows Before |   Rows After |   Duplicates Removed | Date dtype     |\n",
      "|----------+---------------+--------------+----------------------+----------------|\n",
      "| AAPL     |          3774 |         2923 |                  851 | datetime64[ns] |\n",
      "| AMZN     |          3774 |         2923 |                  851 | datetime64[ns] |\n",
      "| GOOG     |          3774 |         2923 |                  851 | datetime64[ns] |\n",
      "| META     |          2923 |         2923 |                    0 | datetime64[ns] |\n",
      "| MSFT     |          3774 |         2923 |                  851 | datetime64[ns] |\n",
      "| NVDA     |          3774 |         2923 |                  851 | datetime64[ns] |\n",
      "+----------+---------------+--------------+----------------------+----------------+\n"
     ]
    }
   ],
   "source": [
    "print(\"Cleaning and aligning datasets:\")\n",
    "\n",
    "summary = []\n",
    "\n",
    "date_sets = [set(pd.to_datetime(df[\"Date\"])) for df in stock_data.values()]\n",
    "common_dates = set.intersection(*date_sets)\n",
    "\n",
    "for ticker, df in stock_data.items():\n",
    "    before_rows = df.shape[0]\n",
    "\n",
    "    # Convert Date column to datetime\n",
    "    df[\"Date\"] = pd.to_datetime(df[\"Date\"], errors=\"coerce\")\n",
    "\n",
    "    # Drop duplicates\n",
    "    df.drop_duplicates(subset=\"Date\", inplace=True)\n",
    "\n",
    "    # Filter to common dates\n",
    "    df = df[df[\"Date\"].isin(common_dates)].copy()\n",
    "\n",
    "    # Sort by date\n",
    "    df.sort_values(\"Date\", inplace=True)\n",
    "\n",
    "    # Adjust index\n",
    "    df.reset_index(drop=True, inplace=True)\n",
    "\n",
    "    # Get after rows\n",
    "    after_rows = df.shape[0]\n",
    "\n",
    "    # Save back to dictionary\n",
    "    stock_data[ticker] = df\n",
    "\n",
    "    summary.append(\n",
    "        {\n",
    "            \"Ticker\": ticker,\n",
    "            \"Rows Before\": before_rows,\n",
    "            \"Rows After\": after_rows,\n",
    "            \"Duplicates Removed\": before_rows - after_rows,\n",
    "            \"Date dtype\": df[\"Date\"].dtype,\n",
    "        }\n",
    "    )\n",
    "\n",
    "print(tabulate(summary, headers=\"keys\", tablefmt=\"psql\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "278ea4f2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Analysis with TA-Lib\n",
      "+----------+--------------+----------+----------+----------+--------+---------------+-------------+\n",
      "| Ticker   |   Total Rows |   SMA_20 |   EMA_20 |   RSI_14 |   MACD |   MACD_Signal |   MACD_Hist |\n",
      "|----------+--------------+----------+----------+----------+--------+---------------+-------------|\n",
      "| AAPL     |         2923 |   192.49 |   191.43 |    51.12 | 1.5595 |        2.4246 |     -0.8651 |\n",
      "| AMZN     |         2923 |   149.82 |   150.21 |    59.01 | 2.782  |        2.923  |     -0.141  |\n",
      "| GOOG     |         2923 |   135.98 |   137.41 |    59.31 | 1.8428 |        1.3059 |      0.5369 |\n",
      "| META     |         2923 |   336.87 |   341.66 |    64.3  | 8.1933 |        6.6935 |      1.4998 |\n",
      "| MSFT     |         2923 |   367.79 |   367.79 |    57.95 | 2.6536 |        3.1496 |     -0.496  |\n",
      "| NVDA     |         2923 |    48.05 |    48.49 |    58.31 | 0.6975 |        0.6352 |      0.0624 |\n",
      "+----------+--------------+----------+----------+----------+--------+---------------+-------------+\n"
     ]
    }
   ],
   "source": [
    "print(\"Analysis with TA-Lib\")\n",
    "\n",
    "indicators_data = {}\n",
    "summary = []\n",
    "\n",
    "for ticker, df in stock_data.items():\n",
    "    temp = df.copy()\n",
    "\n",
    "    temp[\"SMA_20\"] = talib.SMA(temp[\"Close\"], timeperiod=20)\n",
    "\n",
    "    temp[\"EMA_20\"] = talib.EMA(temp[\"Close\"], timeperiod=20)\n",
    "\n",
    "    temp[\"RSI_14\"] = talib.RSI(temp[\"Close\"], timeperiod=14)\n",
    "\n",
    "    macd, macd_signal, macd_hist = talib.MACD(\n",
    "        temp[\"Close\"], fastperiod=12, slowperiod=26, signalperiod=9\n",
    "    )\n",
    "    temp[\"MACD\"] = macd\n",
    "    temp[\"MACD_Signal\"] = macd_signal\n",
    "    temp[\"MACD_Hist\"] = macd_hist\n",
    "\n",
    "    indicators_data[ticker] = temp\n",
    "    last_row = temp.iloc[-1]\n",
    "    summary.append(\n",
    "        {\n",
    "            \"Ticker\": ticker,\n",
    "            \"Total Rows\": temp.shape[0],\n",
    "            \"SMA_20\": round(last_row[\"SMA_20\"], 2),\n",
    "            \"EMA_20\": round(last_row[\"EMA_20\"], 2),\n",
    "            \"RSI_14\": round(last_row[\"RSI_14\"], 2),\n",
    "            \"MACD\": round(last_row[\"MACD\"], 4),\n",
    "            \"MACD_Signal\": round(last_row[\"MACD_Signal\"], 4),\n",
    "            \"MACD_Hist\": round(last_row[\"MACD_Hist\"], 4),\n",
    "        }\n",
    "    )\n",
    "\n",
    "print(tabulate(summary, headers=\"keys\", tablefmt=\"psql\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "c3133c2c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Calculating financial metrics with PyNance\n",
      "+----------+------------+-------------------------+----------------+--------------------+-------------------------+\n",
      "| Ticker   |   CAGR (%) |   Annual Volatility (%) |   Sharpe Ratio |   Max Drawdown (%) |   Last Daily Return (%) |\n",
      "|----------+------------+-------------------------+----------------+--------------------+-------------------------|\n",
      "| AAPL     |      23.85 |                   28.41 |       -34.5845 |             -43.8  |                   -0.54 |\n",
      "| AMZN     |      25.67 |                   32.35 |       -30.2927 |             -56.15 |                   -0.94 |\n",
      "| GOOG     |      21.31 |                   27.16 |       -36.26   |             -44.6  |                   -0.25 |\n",
      "| META     |      21.12 |                   40.13 |       -24.4386 |             -76.74 |                   -1.22 |\n",
      "| MSFT     |      26.93 |                   26.59 |       -36.8748 |             -37.15 |                    0.2  |\n",
      "| NVDA     |      56.29 |                   44.16 |       -21.5928 |             -66.34 |                    0    |\n",
      "+----------+------------+-------------------------+----------------+--------------------+-------------------------+\n"
     ]
    }
   ],
   "source": [
    "print(\"Calculating financial metrics with PyNance\")\n",
    "\n",
    "\n",
    "summary = []\n",
    "\n",
    "for ticker, df in stock_data.items():\n",
    "    temp = df.copy()\n",
    "    temp[\"Date\"] = pd.to_datetime(temp[\"Date\"])\n",
    "    temp = temp.set_index(\"Date\").sort_index()\n",
    "    prices = temp[\"Close\"]\n",
    "    returns = prices.pct_change().dropna()\n",
    "\n",
    "    # Time period in years\n",
    "    years = (prices.index[-1] - prices.index[0]).days / 365.25\n",
    "\n",
    "    # CAGR - most accurate method\n",
    "    cagr = (prices.iloc[-1] / prices.iloc[0]) ** (1 / years) - 1\n",
    "\n",
    "    summary.append(\n",
    "        {\n",
    "            \"Ticker\": ticker,\n",
    "            \"CAGR (%)\": round(cagr * 100, 2),\n",
    "            \"Annual Volatility (%)\": round(ep.annual_volatility(returns) * 100, 2),\n",
    "            \"Sharpe Ratio\": round(ep.sharpe_ratio(returns, risk_free=0.04) * 100, 2)\n",
    "            / 100,  # round to 2 decimals\n",
    "            \"Max Drawdown (%)\": round(ep.max_drawdown(returns) * 100, 2),\n",
    "            \"Last Daily Return (%)\": round(returns.iloc[-1] * 100, 2),\n",
    "        }\n",
    "    )\n",
    "\n",
    "print(tabulate(summary, headers=\"keys\", tablefmt=\"psql\"))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
